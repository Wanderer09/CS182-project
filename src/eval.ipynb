{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9cc648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import re\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from eval import get_run_metrics, read_run_dir, get_model_from_run\n",
    "from plot_utils import basic_plot, collect_results, relevant_model_names\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set_theme('notebook', 'darkgrid')\n",
    "palette = sns.color_palette('colorblind')\n",
    "\n",
    "run_dir = \"../models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8d018b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>kwargs</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>n_dims</th>\n",
       "      <th>n_layer</th>\n",
       "      <th>n_head</th>\n",
       "      <th>run_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>depth=4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>decision_tree_pretrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>linear_regression_pretrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba0ee95e-ee88-4a08-ae9b-3fc39b4d47ae</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>linear_regression_toy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>polynomial_regression_1dim</td>\n",
       "      <td>Transformer</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>polynomial_regression_1_dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>relu_2nn_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>hidden_layer_size=100</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>relu_2nn_regression_pretrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>sine_task</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>A_range=[0.1, 5.0]_B_range=[0.1, 5.0]_C_range=...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>sine_task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>sparse_linear_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>sparsity=3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>sparse_regression_pretrained</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 run_id                        task  \\\n",
       "4                            pretrained               decision_tree   \n",
       "1                            pretrained           linear_regression   \n",
       "2  ba0ee95e-ee88-4a08-ae9b-3fc39b4d47ae           linear_regression   \n",
       "6                            pretrained  polynomial_regression_1dim   \n",
       "0                            pretrained         relu_2nn_regression   \n",
       "5                            pretrained                   sine_task   \n",
       "3                            pretrained    sparse_linear_regression   \n",
       "\n",
       "         model                                             kwargs  num_tasks  \\\n",
       "4  Transformer                                            depth=4         -1   \n",
       "1  Transformer                                                            -1   \n",
       "2  Transformer                                                            -1   \n",
       "6  Transformer                                                            -1   \n",
       "0  Transformer                              hidden_layer_size=100         -1   \n",
       "5  Transformer  A_range=[0.1, 5.0]_B_range=[0.1, 5.0]_C_range=...         -1   \n",
       "3  Transformer                                         sparsity=3         -1   \n",
       "\n",
       "   num_examples  n_dims  n_layer  n_head                        run_name  \n",
       "4            -1      20       12       8        decision_tree_pretrained  \n",
       "1            -1      20       12       8    linear_regression_pretrained  \n",
       "2            -1       5       12       8           linear_regression_toy  \n",
       "6            -1       1       12       8     polynomial_regression_1_dim  \n",
       "0            -1      20       12       8  relu_2nn_regression_pretrained  \n",
       "5            -1       5       12       8                       sine_task  \n",
       "3            -1      20       12       8    sparse_regression_pretrained  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_run_dir(run_dir)\n",
    "df  # list all the runs in our run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9980951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task = \"linear_regression\"\n",
    "#task = \"sparse_linear_regression\"\n",
    "#task = \"decision_tree\"\n",
    "#task = \"relu_2nn_regression\"\n",
    "task = \"polynomial_regression_1dim\"\n",
    "\n",
    "run_id = \"pretrained\"  # if you train more models, replace with the run_id from the table above\n",
    "\n",
    "run_path = os.path.join(run_dir, task, run_id)\n",
    "recompute_metrics = False\n",
    "\n",
    "if recompute_metrics:\n",
    "    get_run_metrics(run_path)  # these are normally precomputed at the end of training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d09964",
   "metadata": {},
   "source": [
    "# Plot pre-computed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07babca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (51) must match the size of tensor b (101) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01meval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_run_metrics\n\u001b[1;32m      3\u001b[0m run_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, task, run_id)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mget_run_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_baselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/in-context-learning/src/eval.py:328\u001b[0m, in \u001b[0;36mget_run_metrics\u001b[0;34m(run_path, step, cache, skip_model_load, skip_baselines)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m checkpoint_created \u001b[38;5;241m>\u001b[39m cache_created:\n\u001b[1;32m    326\u001b[0m         recompute \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m all_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_evals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecompute\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_metrics\n",
      "File \u001b[0;32m~/in-context-learning/src/eval.py:290\u001b[0m, in \u001b[0;36mcompute_evals\u001b[0;34m(all_models, evaluation_kwargs, save_path, recompute)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m metrics \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m recompute:\n\u001b[1;32m    288\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m         metrics[model\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     all_metrics[eval_name] \u001b[38;5;241m=\u001b[39m metrics\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/in-context-learning/src/eval.py:194\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(model, task_name, data_name, n_dims, n_points, prompting_strategy, num_eval_examples, batch_size, data_sampler_kwargs, task_sampler_kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_eval_examples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size):\n\u001b[1;32m    192\u001b[0m     xs, xs_p \u001b[38;5;241m=\u001b[39m generating_func(data_sampler, n_points, batch_size)\n\u001b[0;32m--> 194\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43meval_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_sampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs_p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     all_metrics\u001b[38;5;241m.\u001b[39mappend(metrics)\n\u001b[1;32m    197\u001b[0m metrics \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(all_metrics, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/in-context-learning/src/eval.py:56\u001b[0m, in \u001b[0;36meval_batch\u001b[0;34m(model, task_sampler, xs, xs_p)\u001b[0m\n\u001b[1;32m     53\u001b[0m     ys_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([ys_context, ys_pad], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B, T)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(xs\u001b[38;5;241m.\u001b[39mto(device), ys_input\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mdetach()  \u001b[38;5;66;03m# (B, T-K)\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     b_size, n_points, _ \u001b[38;5;241m=\u001b[39m xs\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/in-context-learning/src/tasks.py:7\u001b[0m, in \u001b[0;36msquared_error\u001b[0;34m(ys_pred, ys)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msquared_error\u001b[39m(ys_pred, ys):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mys_pred\u001b[49m)\u001b[38;5;241m.\u001b[39msquare()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (51) must match the size of tensor b (101) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from eval import get_run_metrics\n",
    "\n",
    "run_path = os.path.join(run_dir, task, run_id)\n",
    "get_run_metrics(run_path, skip_baselines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e02c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def valid_row(r):\n",
    "    return r.task == task and r.run_id == run_id\n",
    "\n",
    "metrics = collect_results(run_dir, df, valid_row=valid_row)\n",
    "_, conf = get_model_from_run(run_path, only_conf=True)\n",
    "n_dims = conf.model.n_dims\n",
    "\n",
    "models = relevant_model_names[task]\n",
    "basic_plot(metrics[\"standard\"], models=models)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4ecca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot any OOD metrics\n",
    "for name, metric in metrics.items():\n",
    "    if name == \"standard\": continue\n",
    "   \n",
    "    if \"scale\" in name:\n",
    "        scale = float(name.split(\"=\")[-1])**2\n",
    "    else:\n",
    "        scale = 1.0\n",
    "\n",
    "    trivial = 1.0 if \"noisy\" not in name else (1+1/n_dims)\n",
    "    fig, ax = basic_plot(metric, models=models, trivial=trivial * scale)\n",
    "    ax.set_title(name)\n",
    "    \n",
    "    if \"ortho\" in name:\n",
    "        ax.set_xlim(-1, n_dims - 1)\n",
    "    ax.set_ylim(-.1 * scale, 1.5 * scale)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f961d4",
   "metadata": {},
   "source": [
    "# Interactive setup\n",
    "\n",
    "We will now directly load the model and measure its in-context learning ability on a batch of random inputs. (In the paper we average over multiple such batches to obtain better estimates.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb327ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from samplers import get_data_sampler\n",
    "from tasks import get_task_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03523b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, conf = get_model_from_run(run_path)\n",
    "\n",
    "n_dims = conf.model.n_dims\n",
    "batch_size = conf.training.batch_size\n",
    "\n",
    "data_sampler = get_data_sampler(conf.training.data, n_dims)\n",
    "task_sampler = get_task_sampler(\n",
    "    conf.training.task,\n",
    "    n_dims,\n",
    "    batch_size,\n",
    "    **conf.training.task_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9da7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task_sampler()\n",
    "xs = data_sampler.sample_xs(b_size=batch_size, n_points=conf.training.curriculum.points.end)\n",
    "ys = task.evaluate(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb69ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa97fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = task.get_metric()\n",
    "loss = metric(pred, ys).numpy()\n",
    "\n",
    "sparsity = conf.training.task_kwargs.sparsity if \"sparsity\" in conf.training.task_kwargs else None\n",
    "baseline = {\n",
    "    \"linear_regression\": n_dims,\n",
    "    \"sparse_linear_regression\": sparsity,\n",
    "    \"relu_2nn_regression\": n_dims,\n",
    "    \"decision_tree\": 1,\n",
    "}[conf.training.task]\n",
    "\n",
    "plt.plot(loss.mean(axis=0), lw=2, label=\"Transformer\")\n",
    "plt.axhline(baseline, ls=\"--\", color=\"gray\", label=\"zero estimator\")\n",
    "plt.xlabel(\"# in-context examples\")\n",
    "plt.ylabel(\"squared error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae775a1",
   "metadata": {},
   "source": [
    "As an exploration example, let's see how robust the model is to doubling all the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58e04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs2 = 2 * xs\n",
    "ys2 = task.evaluate(xs2)\n",
    "with torch.no_grad():\n",
    "    pred2 = model(xs2, ys2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea71ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 = metric(pred2, ys2).numpy()\n",
    "\n",
    "plt.plot(loss.mean(axis=0), lw=2, label=\"Transformer\")\n",
    "plt.plot(loss2.mean(axis=0) / 4, lw=2, label=\"Transformer on doubled inputs\")\n",
    "plt.axhline(baseline, ls=\"--\", color=\"gray\", label=\"zero estimator\")\n",
    "plt.xlabel(\"# in-context examples\")\n",
    "plt.ylabel(\"squared error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021f118e",
   "metadata": {},
   "source": [
    "The error does increase, especially when the number of in-context examples exceeds the dimension, but the model is still relatively accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc9cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in-context-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
